# -*- coding: utf-8 -*-
"""Credit card fraud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kfv8WyOEGCXluACxqHmS5ZUI_Z93chen
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

credit_card_data = pd.read_csv("/content/creditcard.csv", error_bad_lines=False);

#kako izgledaju podaci
credit_card_data.head().append(credit_card_data.tail())

#informacije o podacima
credit_card_data.info()

#proveravamo da li negde fale podaci
credit_card_data.isnull().sum()

#šta treba da predvidimo?
credit_card_data['Class'].value_counts()

#deljenje podataka
fraud = credit_card_data[credit_card_data.Class == 1]
good = credit_card_data[credit_card_data.Class == 0]

print(good.shape)
print(fraud.shape)

#deskriptivna statistika
good.Amount.describe()

fraud.Amount.describe()

#kada ih uporedimo:
credit_card_data.groupby('Class').mean()

#napravićemo novi dataset koji posmatra sličnu distribuciju tranzakcija
good_sample = good.sample(n=492)
new_dataset = pd.concat([good_sample, fraud], axis=0)
new_dataset.head()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()
x = new_dataset.drop(columns='Class', axis=1)
y = new_dataset['Class']
print(x)

print(y)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2)
print(x.shape, x_train.shape, x_test.shape)

model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)

model.fit(x_train, y_train)

x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction, y_train)

print('Accuracy on Training data : ', training_data_accuracy)

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
x_test_prediction = model.predict(x_test)
accuracy1 = accuracy_score(x_test_prediction, y_test)
precision1=precision_score(x_test_prediction, y_test)
recall1=recall_score(x_test_prediction, y_test)
fscore1=f1_score(x_test_prediction, y_test)
print('Accuracy score:', accuracy1)
print('\n Precision :\n',precision1 )
print("\n Recall :\n", recall1)
print("\n F1 Skor :\n", fscore1)

from sklearn.tree import DecisionTreeClassifier
classifier=DecisionTreeClassifier(max_depth=4)
classifier.fit(x_train, y_train)
predicted=classifier.predict(x_test)
print("\n Predicted value:\n",predicted)

from sklearn import metrics
DecisionTree= metrics.accuracy_score(y_test, predicted) * 100
print("\n The Accuracy Score : ", DecisionTree)



precision=precision_score(y_test, predicted, pos_label=1)*100
print('\n Precision :\n',precision )

recall=recall_score(y_test, predicted, pos_label=1)*100
print("\n Recall :\n", recall)

fscore=f1_score(y_test, predicted, pos_label=1)*100
print("\n F1 Skor :\n", fscore)

from sklearn.metrics import roc_curve, roc_auc_score
clf_tree = DecisionTreeClassifier();
clf_reg = LogisticRegression();
clf_tree.fit(x_train, y_train); 
clf_reg.fit(x_train, y_train);

y_score1 = clf_tree.predict_proba(x_test)[:,1]
  y_score2 = clf_reg.predict_proba(x_test)[:,1]
  false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, y_score1)
  false_positive_rate2, true_positive_rate2, threshold2 = roc_curve(y_test, y_score2)
  print('roc_auc_score for DecisionTree: ', roc_auc_score(y_test, y_score1))
  print('roc_auc_score for Logistic Regression: ', roc_auc_score(y_test, y_score2))

import matplotlib.pyplot as plt
plt.subplots(1, figsize=(10,10))
plt.title('Receiver Operating Characteristic - DecisionTree')
plt.plot(false_positive_rate1, true_positive_rate1)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

plt.subplots(1, figsize=(10,10))
plt.title('Receiver Operating Characteristic - Logistic regression')
plt.plot(false_positive_rate2, true_positive_rate2)
plt.plot([0, 1], ls="--")
plt.plot([0, 0], [1, 0] , c=".7"), plt.plot([1, 1] , c=".7")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.metrics import confusion_matrix
print("Decision Tree Confusion Matrix: ", confusion_matrix(y_test, x_test_prediction))
print("Logistic Regression Confusion Matrix: ", confusion_matrix(y_test, predicted))

from sklearn.metrics import classification_report
print("Decision Tree Classification Report: ", classification_report(y_test, x_test_prediction))
print("Logistic Regression Classification Report: ", classification_report(y_test, predicted))